{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicTree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOh23KMjRF45cVNLC2Yiozq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnitnaw/Programs/blob/master/Chapter8/BasicTree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaWHJhVsAblT",
        "outputId": "f85f2a6b-74fc-4c56-dd8e-5297836d6fc8"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LetQC4wyAgKh"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bXKlDOvAoW5",
        "outputId": "62886e8d-583c-403c-ce1f-92f7bc757946"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_friedman1\n",
        "from sklearn.model_selection import train_test_split\n",
        "print(np.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.21.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmrPRrN05iIF"
      },
      "source": [
        "## Set random seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdzVvsn_5lIf"
      },
      "source": [
        "np.random.seed(1357)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYGyiNcLBI8j"
      },
      "source": [
        "## Original Program"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OGRmXk9BLh2",
        "outputId": "fce3525f-e938-4d82-e15c-ba29e3623171"
      },
      "source": [
        "def makedata():\n",
        "  n_points = 500 # points\n",
        " \n",
        "  X, y =  make_friedman1(n_samples=n_points, n_features=5, \n",
        "                         noise=1.0, random_state=100)\n",
        "         \n",
        "  return train_test_split(X, y, test_size=0.5, random_state=3)\n",
        "  \n",
        " \n",
        "def main():\n",
        "  X_train, X_test, y_train, y_test = makedata()    \n",
        "  maxdepth = 10 # maximum tree depth             \n",
        "  # Create tree root at depth 0                       \n",
        "  treeRoot = TNode(0, X_train,y_train) \n",
        "       \n",
        "  # Build the regression tree with maximal depth equal to max_depth\n",
        "  Construct_Subtree(treeRoot, maxdepth) \n",
        "    \n",
        "  # Predict\n",
        "  y_hat = np.zeros(len(X_test))\n",
        "  for i in range(len(X_test)):\n",
        "     y_hat[i] = Predict(X_test[i],treeRoot)          \n",
        "    \n",
        "  MSE = np.mean(np.power(y_hat - y_test,2))    \n",
        "  print(\"Basic tree: tree loss = \",  MSE)\n",
        "\n",
        "# tree node\n",
        "class TNode:\n",
        "   def __init__(self, depth, X, y): \n",
        "      self.depth = depth\n",
        "      self.X = X   # matrix of explanatory variables\n",
        "      self.y = y   # vector of response variables\n",
        "      # initialize optimal split parameters\n",
        "      self.j = None\n",
        "      self.xi = None\n",
        "      # initialize children to be None      \n",
        "      self.left = None\n",
        "      self.right = None\n",
        "      # initialize the regional predictor\n",
        "      self.g = None\n",
        "      \n",
        "   def CalculateLoss(self):\n",
        "       if(len(self.y)==0):\n",
        "           return 0\n",
        "       \n",
        "       return np.sum(np.power(self.y- self.y.mean(),2))\n",
        "                    \n",
        "  \n",
        "def Construct_Subtree(node, max_depth):  \n",
        "    if(node.depth == max_depth or len(node.y) == 1):\n",
        "        node.g  = node.y.mean()\n",
        "    else:\n",
        "        j, xi = CalculateOptimalSplit(node)               \n",
        "        node.j = j\n",
        "        node.xi = xi\n",
        "        Xt, yt, Xf, yf = DataSplit(node.X, node.y, j, xi)\n",
        "              \n",
        "        if(len(yt)>0):\n",
        "            node.left = TNode(node.depth+1,Xt,yt)\n",
        "            Construct_Subtree(node.left, max_depth)\n",
        "        \n",
        "        if(len(yf)>0):        \n",
        "            node.right = TNode(node.depth+1, Xf,yf)\n",
        "            Construct_Subtree(node.right, max_depth)      \n",
        "     \n",
        "    return node\n",
        "\n",
        "# split the data-set\n",
        "def DataSplit(X,y,j,xi):\n",
        "    ids = X[:,j]<=xi      \n",
        "    Xt  = X[ids == True,:]\n",
        "    Xf  = X[ids == False,:]\n",
        "    yt  = y[ids == True]\n",
        "    yf  = y[ids == False]\n",
        "    return Xt, yt, Xf, yf             \n",
        "\n",
        "def CalculateOptimalSplit(node):\n",
        "    X = node.X\n",
        "    y = node.y\n",
        "    best_var = 0\n",
        "    best_xi = X[0,best_var]          \n",
        "    best_split_val = node.CalculateLoss()\n",
        "    \n",
        "    m, n  = X.shape\n",
        "    \n",
        "    for j in range(0,n):\n",
        "        for i in range(0,m):\n",
        "            xi = X[i,j]\n",
        "            Xt, yt, Xf, yf = DataSplit(X,y,j,xi)\n",
        "            tmpt = TNode(0, Xt, yt) \n",
        "            tmpf = TNode(0, Xf, yf) \n",
        "            loss_t = tmpt.CalculateLoss()\n",
        "            loss_f = tmpf.CalculateLoss()    \n",
        "            curr_val =  loss_t + loss_f\n",
        "            if (curr_val < best_split_val):\n",
        "                best_split_val = curr_val\n",
        "                best_var = j\n",
        "                best_xi = xi\n",
        "    return best_var,  best_xi\n",
        "\n",
        "\n",
        "def Predict(X,node):\n",
        "    if(node.right == None and node.left != None):\n",
        "        return Predict(X,node.left)\n",
        "    \n",
        "    if(node.right != None and node.left == None):\n",
        "        return Predict(X,node.right)\n",
        "    \n",
        "    if(node.right == None and node.left == None):\n",
        "        return node.g\n",
        "    else:\n",
        "        if(X[node.j] <= node.xi):\n",
        "            return Predict(X,node.left)\n",
        "        else:\n",
        "            return Predict(X,node.right)\n",
        "    \n",
        "main()  # run the main program\n",
        "\n",
        "# compare with sklearn\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "X_train, X_test, y_train, y_test = makedata()    \n",
        "regTree = DecisionTreeRegressor(max_depth = 10, random_state=0)\n",
        "regTree.fit(X_train,y_train)\n",
        "y_hat = regTree.predict(X_test)\n",
        "MSE2 = np.mean(np.power(y_hat - y_test,2))    \n",
        "print(\"DecisionTreeRegressor: tree loss = \",  MSE2)     \n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic tree: tree loss =  9.067077996170276\n",
            "DecisionTreeRegressor: tree loss =  10.197991295531748\n"
          ]
        }
      ]
    }
  ]
}